{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyHQwEBeDSHdivkJIP8TD1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LostUniavan/ScikitLearn/blob/main/ScikitLearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28PJOz9PHhZL",
        "outputId": "04fc6ec9-397e-4097-abb1-f915b29197d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento começou em: 2024-07-05 00:46:15\n",
            "Treinamento finalizado em 190 epochs. Com um erro final de 0.11286223900281867\n",
            "Treinamento finalizado em: 2024-07-05 00:46:17\n",
            "Teste com os dados de treinamento vs resultado esperado, Correto: 203, Incorreto: 7\n",
            "Nível de ruído: 2.0%, Correto: 200, Incorreto: 10\n",
            "Nível de ruído: 5.0%, Correto: 191, Incorreto: 19\n",
            "Nível de ruído: 10.0%, Correto: 137, Incorreto: 73\n",
            "Nível de ruído: 30.0%, Correto: 16, Incorreto: 194\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import time\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def prepare_csv(input_file, output_file):\n",
        "    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
        "        reader = csv.reader(infile)\n",
        "        writer = csv.writer(outfile)\n",
        "\n",
        "        for i, row in enumerate(reader):\n",
        "            label = i\n",
        "            row.append(label)\n",
        "            writer.writerow(row)\n",
        "\n",
        "def apply_visual_noise(data, noise_level):\n",
        "    noisy_data = data.copy()\n",
        "    num_elements = noisy_data.size\n",
        "\n",
        "    ones_indices = np.where(noisy_data == 1)[0]\n",
        "    zeros_indices = np.where(noisy_data == 0)[0]\n",
        "\n",
        "    num_noisy_ones = int(len(ones_indices) * noise_level)\n",
        "    num_noisy_zeros = int(len(zeros_indices) * noise_level)\n",
        "\n",
        "    noisy_ones_indices = np.random.choice(ones_indices, num_noisy_ones, replace=False)\n",
        "    noisy_zeros_indices = np.random.choice(zeros_indices, num_noisy_zeros, replace=False)\n",
        "\n",
        "    for index in noisy_ones_indices:\n",
        "        noisy_data.flat[index] = 0\n",
        "    for index in noisy_zeros_indices:\n",
        "        noisy_data.flat[index] = 1\n",
        "\n",
        "    return noisy_data\n",
        "\n",
        "def evaluate_mlp_with_visual_noise(mlp, test_data, expected_outputs, noise_levels):\n",
        "    for noise_level in noise_levels:\n",
        "        noisy_inputs = np.array([apply_visual_noise(x, noise_level) for x in test_data])\n",
        "        predictions = mlp.predict(noisy_inputs)\n",
        "        accuracy = accuracy_score(expected_outputs, predictions)\n",
        "        correct = int(accuracy * len(test_data))\n",
        "        incorrect = len(test_data) - correct\n",
        "        print(f\"Nível de ruído: {noise_level*100}%, Correto: {correct}, Incorreto: {incorrect}\")\n",
        "\n",
        "input_file = 'data_input.csv'\n",
        "output_file = 'data_input_preparado.csv'\n",
        "prepare_csv(input_file, output_file)\n",
        "\n",
        "data = np.loadtxt(output_file, delimiter=',')\n",
        "inputs = data[:, :-1]\n",
        "expected_outputs = data[:, -1]\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), activation='tanh', solver='adam', learning_rate_init=0.01, max_iter=5000)\n",
        "start_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
        "print(f\"Treinamento começou em: {start_time}\")\n",
        "mlp.fit(inputs, expected_outputs)\n",
        "end_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
        "print(f\"Treinamento finalizado em {mlp.n_iter_} epochs. Com um erro final de {mlp.loss_}\")\n",
        "print(f\"Treinamento finalizado em: {end_time}\")\n",
        "\n",
        "predictions = mlp.predict(inputs)\n",
        "accuracy = accuracy_score(expected_outputs, predictions)\n",
        "correct = int(accuracy * len(inputs))\n",
        "incorrect = len(inputs) - correct\n",
        "print(f\"Teste com os dados de treinamento vs resultado esperado, Correto: {correct}, Incorreto: {incorrect}\")\n",
        "\n",
        "noise_levels = [0.02, 0.05, 0.1, 0.3]\n",
        "evaluate_mlp_with_visual_noise(mlp, inputs, expected_outputs, noise_levels)\n"
      ]
    }
  ]
}